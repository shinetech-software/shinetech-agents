{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44f0c283",
   "metadata": {},
   "source": [
    "### 采用预训练模型做词嵌入处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8e881d-65cf-4b41-b406-a297b248b977",
   "metadata": {},
   "source": [
    "1. 导入数据到csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1a6221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "# 数据库连接参数\n",
    "server = ''  # 服务器名称或IP地址\n",
    "database = ''  # 数据库名称\n",
    "username = ''  # 用户名\n",
    "password = ''  # 密码\n",
    "driver = 'ODBC Driver 17 for SQL Server'\n",
    "\n",
    "connection_string = f'mssql+pyodbc://{username}:{password}@{server}/{database}?driver={driver}'\n",
    "engin = create_engine(connection_string)\n",
    "\n",
    "RowData = pd.read_sql('''SELECT LeadGUID, LeadNo, FirstName, LastName, CompanyName, MobilePhone, \n",
    "                      TellPhone, Email, TypedCountry, Description, ConvertToLead FROM LeadFromSHNWebSite \n",
    "                      WHERE SysCountryID <> 7 AND RequestDate IS NOT NULL AND Description IS NOT NULL AND CreateUser = \\'System\\'''', engin)\n",
    "\n",
    "RowData.to_csv('data.csv', index=False)\n",
    "engin.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd562b5",
   "metadata": {},
   "source": [
    "2. 读取CSV文件，并通过tokenizer进行分词统计，以找到最大token长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8bb6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download()\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "maxLength = 0\n",
    "for index, row in df.iterrows():\n",
    "    if pd.notna(row['Description']):\n",
    "        token = nltk.word_tokenize(row['Description'])\n",
    "        if len(token) > maxLength:\n",
    "            maxLength = len(token)\n",
    "print(maxLength)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c2532b",
   "metadata": {},
   "source": [
    "3. 采用SentenceTransformer对文本进行嵌入，示例如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa58542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "sentences = [\"This is the first sentence\", \"This is the second sentence\"]\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8264fb1",
   "metadata": {},
   "source": [
    "注意：该模型最大输入token长度为256，我们需要采用Padding算法或者滑窗算法对长文本做处理，以准确获得384维向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c63c3a",
   "metadata": {},
   "source": [
    "4. 采用BGE-M3算法做词嵌入，示例如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d39d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "\n",
    "model = BGEM3FlagModel('BAAI/bge-m3',  \n",
    "                       use_fp16=True) # 设置fp16为True，可以加速模型推理\n",
    "\n",
    "sentences_1 = [\"What is BGE M3?\", \"Defination of BM25\"]\n",
    "sentences_2 = [\"BGE M3 is an embedding model supporting dense retrieval, lexical matching and multi-vector interaction.\", \n",
    "               \"BM25 is a bag-of-words retrieval function that ranks a set of documents based on the query terms appearing in each document\"]\n",
    "\n",
    "embeddings_1 = model.encode(sentences_1, \n",
    "                            batch_size=12, \n",
    "                            max_length=8192,\n",
    "                            )['dense_vecs']\n",
    "embeddings_2 = model.encode(sentences_2)['dense_vecs']\n",
    "similarity = embeddings_1 @ embeddings_2.T # 向量内积\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beda6984",
   "metadata": {},
   "source": [
    "5. 数据基本清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89514e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_url(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'website', text)\n",
    "\n",
    "def remove_emails(text):\n",
    "    email_pattern = re.compile(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b')\n",
    "    return email_pattern.sub('email', text)\n",
    "\n",
    "def remove_ids(text):\n",
    "    pattern = re.compile(r'\\[.*?\\]')\n",
    "    return pattern.sub('', text)\n",
    "\n",
    "def remove_non_ascii(text):\n",
    "    non_ascii_pattern = re.compile(r'[^\\x00-\\x7F]+')\n",
    "    return non_ascii_pattern.sub('', text)\n",
    "\n",
    "def clean(text):\n",
    "    cleaned_text = clean_url(text)\n",
    "    cleaned_text = remove_emails(cleaned_text)\n",
    "    cleaned_text = remove_ids(cleaned_text)\n",
    "    cleaned_text = remove_non_ascii(cleaned_text)\n",
    "    return cleaned_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
